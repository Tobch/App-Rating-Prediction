{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e017413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b591dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition\\path\\train.csv\")\n",
    "df.rename(columns={\n",
    "    'X0': 'AppName',\n",
    "    'X1': 'Category',\n",
    "    'X2': 'NumReviews',\n",
    "    'X3': 'AppSize',\n",
    "    'X4': 'NumInstalls',\n",
    "    'X5': 'IsFree',\n",
    "    'X6': 'Price',\n",
    "    'X7': 'AgeCategory',\n",
    "    'X8': 'Genres',\n",
    "    'X9': 'LastUpdate',\n",
    "    'X10': 'Version',\n",
    "    'X11': 'MinAndroidVer',\n",
    "    'Y': 'Rating'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop AppName\n",
    "df.drop(columns=['AppName'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42bea21",
   "metadata": {},
   "source": [
    "## Category Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81dd1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove the erroneous '1.9' category row\n",
    "df = df[df['Category'] != '1.9']\n",
    "\n",
    "# Step 2: Group smaller categories to reduce imbalance\n",
    "# Categories with fewer than 50 entries get grouped into \"OTHER\"\n",
    "category_counts = df['Category'].value_counts()\n",
    "small_categories = category_counts[category_counts < 50].index.tolist()\n",
    "df['Category_Grouped'] = df['Category'].apply(\n",
    "    lambda x: 'OTHER' if x in small_categories else x)\n",
    "\n",
    "# Step 3: One-hot encode the grouped categories\n",
    "# This creates binary columns for each category\n",
    "category_dummies = pd.get_dummies(df['Category_Grouped'], prefix='Cat')\n",
    "\n",
    "# Step 4: Join the new dummy columns to the original dataframe\n",
    "df = pd.concat([df, category_dummies], axis=1)\n",
    "\n",
    "# Step 5: Drop the original Category column to avoid redundancy\n",
    "# Keep Category_Grouped for reference if needed\n",
    "df.drop(columns=['Category', 'Category_Grouped'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce624c",
   "metadata": {},
   "source": [
    "## Fixing NumReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93acf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NumReviews\"] = pd.to_numeric(df[\"NumReviews\"], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23366a",
   "metadata": {},
   "source": [
    "## Fixing AppSize & numinstalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce5f7cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tech Trick\\AppData\\Local\\Temp\\ipykernel_13260\\7708076.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"AppSize\"].fillna(app_size_median, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_mb(size_str):\n",
    "    if isinstance(size_str, str):\n",
    "        if 'k' in size_str.lower():\n",
    "            # Convert kilobytes to megabytes (divide by 1024)\n",
    "            return float(size_str.lower().replace('k', '').strip()) / 1024\n",
    "        elif 'm' in size_str.lower():\n",
    "            # Convert megabytes to megabytes (already in the correct unit)\n",
    "            return float(size_str.lower().replace('m', '').strip())\n",
    "        elif 'varies with device' in size_str.lower():\n",
    "            return np.nan\n",
    "        else:\n",
    "            # Already in megabytes\n",
    "            return float(size_str)\n",
    "    return size_str\n",
    "\n",
    "\n",
    "# Apply the conversion function\n",
    "df[\"AppSize\"] = df[\"AppSize\"].apply(convert_to_mb)\n",
    "\n",
    "# Convert to numeric, forcing errors to NaN\n",
    "df[\"AppSize\"] = pd.to_numeric(df[\"AppSize\"], errors='coerce')\n",
    "\n",
    "# Fill NaN values with median of the column\n",
    "app_size_median = df[\"AppSize\"].median()  # We can modify this later\n",
    "\n",
    "df[\"AppSize\"].fillna(app_size_median, inplace=True)\n",
    "\n",
    "entries_where_end_is_plus = df[\"NumInstalls\"].map(lambda x: x.endswith('+'))\n",
    "\n",
    "# Remove the '+' sign and convert to numeric\n",
    "df[\"NumInstalls\"] = df[\"NumInstalls\"].map(\n",
    "    lambda x: x[:-1].replace(',', '') if x.endswith('+') else x)\n",
    "df[\"NumInstalls\"] = pd.to_numeric(df[\"NumInstalls\"], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccc018",
   "metadata": {},
   "source": [
    "## Fixing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f70b67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "C:\\Users\\Tech Trick\\AppData\\Local\\Temp\\ipykernel_13260\\597601396.py:4: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df[\"Price\"] = df[\"Price\"].replace({'\\$': ''}, regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Replace instances of \"Free\" with 0 and \"Paid\" with 1\n",
    "df[\"IsFree\"] = df[\"IsFree\"].map(lambda x: 0 if x == \"Free\" else 1)\n",
    "# Remove dollar sign before converting to numeric\n",
    "df[\"Price\"] = df[\"Price\"].replace({'\\$': ''}, regex=True)\n",
    "df[\"Price\"] = pd.to_numeric(df[\"Price\"], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf96a86b",
   "metadata": {},
   "source": [
    "## Fixing Age Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0abe1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_category_dummies = pd.get_dummies(df['AgeCategory'], prefix='Age')\n",
    "\n",
    "# Add the one-hot encoded columns to the dataframe\n",
    "df = pd.concat([df, age_category_dummies], axis=1)\n",
    "\n",
    "# Optionally, drop the original AgeCategory column if you don't need it anymore\n",
    "df.drop('AgeCategory', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab53484",
   "metadata": {},
   "source": [
    "## Fixing Genres, Year, Version and MinAndroidVersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a9f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre_split'] = df['Genres'].str.split(';')\n",
    "\n",
    "# Step 2: Use MultiLabelBinarizer to create binary columns\n",
    "mlb = MultiLabelBinarizer()\n",
    "genre_encoded = pd.DataFrame(\n",
    "    mlb.fit_transform(df['Genre_split']),\n",
    "    columns=mlb.classes_,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "# Step 3: Combine the original DataFrame with the encoded genres\n",
    "df_encoded = pd.concat([df, genre_encoded], axis=1)\n",
    "\n",
    "# If you want to drop the original and intermediate columns\n",
    "df_encoded = df_encoded.drop(['Genres', 'Genre_split'], axis=1)\n",
    "\n",
    "df = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba3b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Year\"] = df[\"LastUpdate\"]\n",
    "# Dates are in mixed formats, so use format='mixed'\n",
    "df[\"LastUpdate\"] = pd.to_datetime(df[\"LastUpdate\"], format='mixed')\n",
    "\n",
    "# Extract the year into a new column\n",
    "df[\"Year\"] = df[\"LastUpdate\"].dt.year\n",
    "\n",
    "df.drop(columns=[\"LastUpdate\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dda31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Version and MinAndroidVer columns\n",
    "df = df.drop(['Version', 'MinAndroidVer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf8aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to int (0/1)\n",
    "bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "for col in bool_columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# No need to convert int64 columns as they are already numeric\n",
    "\n",
    "# Make sure all float columns are properly formatted\n",
    "float_columns = df.select_dtypes(include=['float64']).columns\n",
    "for col in float_columns:\n",
    "    # Handle any potential non-numeric values\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Make sure Year is properly formatted as numeric\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce').astype('int32')\n",
    "\n",
    "# Handle missing values in Rating (our target variable)\n",
    "# Since Rating is what we're trying to predict, we'll drop rows with missing Rating values\n",
    "df_for_ml = df.dropna(subset=['Rating'])\n",
    "\n",
    "# Assert no NaNs\n",
    "assert df_for_ml.isnull().sum().sum() == 0, \"There are still NaN values in the DataFrame.\"\n",
    "\n",
    "# Assert no text columns\n",
    "assert df_for_ml.select_dtypes(include=['object']).empty, \"There are still text columns in the DataFrame.\"\n",
    "\n",
    "# Assert no infinite values\n",
    "assert not np.isinf(df_for_ml).any().any(), \"There are infinite values in the DataFrame.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4b071",
   "metadata": {},
   "source": [
    "# Save data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00bb28ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved to D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition\\cleaned_train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "cleaned_file = r\"D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition\\cleaned_train.csv\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(cleaned_file), exist_ok=True)\n",
    "\n",
    "df_for_ml.to_csv(cleaned_file, index=False)\n",
    "print(f\"Cleaned DataFrame saved to {cleaned_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c48494",
   "metadata": {},
   "source": [
    "# Normailzation of number of installs and number of reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e263aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DataFrame saved to D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition/normalized_train.csv\n"
     ]
    }
   ],
   "source": [
    "df['NumInstalls'] = np.log1p(df['NumInstalls'])\n",
    "df['NumReviews'] = np.log1p(df['NumReviews']) \n",
    "# add those to the new cleaned dataframe \n",
    "df_for_ml = df.dropna(subset=['Rating'])\n",
    "normalized_file = r\"D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition/normalized_train.csv\"\n",
    "df_for_ml.to_csv(normalized_file, index=False)\n",
    "print(f\"Normalized DataFrame saved to {normalized_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9c786",
   "metadata": {},
   "source": [
    "# Splitting the data into train , validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5f6b7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splits saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#split the data into 70% training and 15% validation and 15% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 70% train, 30% temp\n",
    "train_df, temp_df = train_test_split(df_for_ml, test_size=0.40, random_state=42)\n",
    "\n",
    "# Second split: 15% val, 15% test from the 30% temp\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42)\n",
    "\n",
    "# Ensure the output directory exists\n",
    "output_dir = r\"D:\\asu\\Semester 6 - Spring 23\\CSE472 - Artificial Intelligence\\another version of Der3 version\\App Rating Competition\\after_split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the splits to CSV files\n",
    "train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
    "print(\"Data splits saved to CSV files.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
